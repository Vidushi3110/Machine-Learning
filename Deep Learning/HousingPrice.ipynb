{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIvk0Iylo+r7aSE5WTmjIM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidushiSharma31/ML-DL/blob/main/Deep%20Learning/HousingPrice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "255c4b89"
      },
      "source": [
        "# California Housing Price Prediction using Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0c35219e"
      },
      "source": [
        "### Importing Libraries\n",
        "\n",
        "This cell imports all the necessary libraries for the task, including libraries for numerical operations (numpy), building and training neural networks (tensorflow, keras), loading a dataset (sklearn.datasets), splitting data (sklearn.model_selection), scaling data (sklearn.preprocessing), and evaluating model performance (sklearn.metrics)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "Q1lvYHgGq90Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c909afd"
      },
      "source": [
        "### Loading the Dataset\n",
        "\n",
        "This cell loads the California Housing dataset using scikit-learn's fetch_california_housing function. It separates the features (X) and the target variable (y)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target"
      ],
      "metadata": {
        "id": "bVOwkBqeroMh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "900f4144"
      },
      "source": [
        "### Splitting the Data\n",
        "\n",
        "This cell splits the dataset into training and testing sets. 80% of the data is used for training and 20% for testing. A fixed random_state ensures the split is the same each time the code is run."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "h3LktRsqs4Tb"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43d1c994"
      },
      "source": [
        "### Scaling the Features\n",
        "\n",
        "This cell scales the features using StandardScaler. This is important for neural networks as it helps with faster convergence during training. The scaler is fitted only on the training data to avoid data leakage."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "LU5d5Ucqr8rn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bc68ab5"
      },
      "source": [
        "### Building the Model\n",
        "\n",
        "This cell defines the neural network model using Keras Sequential API. It consists of three hidden layers with ReLU activation and an output layer with linear activation, suitable for regression tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([Dense(64, activation='relu'),\n",
        "                    Dense(32, activation='relu'),\n",
        "                    Dense(16, activation='relu'),\n",
        "                    Dense(1, activation='linear')])"
      ],
      "metadata": {
        "id": "0iagW_ZYsIm_"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e539ea6"
      },
      "source": [
        "### Compiling the Model\n",
        "\n",
        "This cell compiles the model. It uses the Adam optimizer with a learning rate of 1e-3, 'mean_squared_error' as the loss function (appropriate for regression), and 'mae' (Mean Absolute Error) as a metric to monitor during training."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss='mean_squared_error', metrics=['mae'])"
      ],
      "metadata": {
        "id": "cOuwUH7bs7HH"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d2d5863"
      },
      "source": [
        "### Defining Callbacks\n",
        "\n",
        "This cell defines two callbacks: EarlyStopping to stop training when the validation loss stops improving and restore the best weights, and ReduceLROnPlateau to reduce the learning rate when the validation loss plateaus."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)"
      ],
      "metadata": {
        "id": "_YgM3F_v1yFB"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1ebab93"
      },
      "source": [
        "### Training the Model\n",
        "\n",
        "This cell trains the neural network model using the scaled training data. It trains for a maximum of 75 epochs with a batch size of 16. 20% of the training data is used for validation, and the defined callbacks are applied."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs=75, batch_size = 16, validation_split=0.2, callbacks=[early_stop, reduce_lr], verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-yc2tDathEE",
        "outputId": "9a528b02-1a93-4f69-e194-64336f8c949e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2219 - mae: 0.3189 - val_loss: 0.2727 - val_mae: 0.3499 - learning_rate: 6.2500e-05\n",
            "Epoch 2/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2223 - mae: 0.3179 - val_loss: 0.2726 - val_mae: 0.3466 - learning_rate: 6.2500e-05\n",
            "Epoch 3/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.2174 - mae: 0.3158 - val_loss: 0.2723 - val_mae: 0.3487 - learning_rate: 6.2500e-05\n",
            "Epoch 4/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2206 - mae: 0.3188 - val_loss: 0.2727 - val_mae: 0.3509 - learning_rate: 6.2500e-05\n",
            "Epoch 5/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 0.2216 - mae: 0.3173 - val_loss: 0.2724 - val_mae: 0.3493 - learning_rate: 6.2500e-05\n",
            "Epoch 6/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.2163 - mae: 0.3148 - val_loss: 0.2716 - val_mae: 0.3473 - learning_rate: 6.2500e-05\n",
            "Epoch 7/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2185 - mae: 0.3185 - val_loss: 0.2745 - val_mae: 0.3499 - learning_rate: 6.2500e-05\n",
            "Epoch 8/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2259 - mae: 0.3186 - val_loss: 0.2731 - val_mae: 0.3487 - learning_rate: 6.2500e-05\n",
            "Epoch 9/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2190 - mae: 0.3175 - val_loss: 0.2747 - val_mae: 0.3549 - learning_rate: 6.2500e-05\n",
            "Epoch 10/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2238 - mae: 0.3212 - val_loss: 0.2716 - val_mae: 0.3473 - learning_rate: 6.2500e-05\n",
            "Epoch 11/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2144 - mae: 0.3109 - val_loss: 0.2714 - val_mae: 0.3486 - learning_rate: 6.2500e-05\n",
            "Epoch 12/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2209 - mae: 0.3197 - val_loss: 0.2730 - val_mae: 0.3509 - learning_rate: 6.2500e-05\n",
            "Epoch 13/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - loss: 0.2262 - mae: 0.3201 - val_loss: 0.2715 - val_mae: 0.3478 - learning_rate: 6.2500e-05\n",
            "Epoch 14/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2127 - mae: 0.3120 - val_loss: 0.2723 - val_mae: 0.3465 - learning_rate: 6.2500e-05\n",
            "Epoch 15/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2215 - mae: 0.3178 - val_loss: 0.2730 - val_mae: 0.3506 - learning_rate: 6.2500e-05\n",
            "Epoch 16/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2211 - mae: 0.3175 - val_loss: 0.2718 - val_mae: 0.3460 - learning_rate: 6.2500e-05\n",
            "Epoch 17/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2199 - mae: 0.3162 - val_loss: 0.2717 - val_mae: 0.3491 - learning_rate: 3.1250e-05\n",
            "Epoch 18/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2212 - mae: 0.3193 - val_loss: 0.2711 - val_mae: 0.3480 - learning_rate: 3.1250e-05\n",
            "Epoch 19/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2171 - mae: 0.3140 - val_loss: 0.2712 - val_mae: 0.3481 - learning_rate: 3.1250e-05\n",
            "Epoch 20/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2189 - mae: 0.3162 - val_loss: 0.2717 - val_mae: 0.3463 - learning_rate: 3.1250e-05\n",
            "Epoch 21/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2209 - mae: 0.3165 - val_loss: 0.2722 - val_mae: 0.3473 - learning_rate: 3.1250e-05\n",
            "Epoch 22/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2197 - mae: 0.3145 - val_loss: 0.2716 - val_mae: 0.3462 - learning_rate: 3.1250e-05\n",
            "Epoch 23/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.2090 - mae: 0.3105 - val_loss: 0.2709 - val_mae: 0.3481 - learning_rate: 3.1250e-05\n",
            "Epoch 24/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2252 - mae: 0.3199 - val_loss: 0.2708 - val_mae: 0.3479 - learning_rate: 3.1250e-05\n",
            "Epoch 25/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2191 - mae: 0.3181 - val_loss: 0.2707 - val_mae: 0.3477 - learning_rate: 3.1250e-05\n",
            "Epoch 26/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2222 - mae: 0.3157 - val_loss: 0.2710 - val_mae: 0.3471 - learning_rate: 3.1250e-05\n",
            "Epoch 27/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2168 - mae: 0.3150 - val_loss: 0.2712 - val_mae: 0.3469 - learning_rate: 3.1250e-05\n",
            "Epoch 28/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2189 - mae: 0.3172 - val_loss: 0.2706 - val_mae: 0.3487 - learning_rate: 3.1250e-05\n",
            "Epoch 29/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2124 - mae: 0.3112 - val_loss: 0.2705 - val_mae: 0.3460 - learning_rate: 3.1250e-05\n",
            "Epoch 30/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2177 - mae: 0.3156 - val_loss: 0.2711 - val_mae: 0.3468 - learning_rate: 3.1250e-05\n",
            "Epoch 31/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2122 - mae: 0.3109 - val_loss: 0.2711 - val_mae: 0.3469 - learning_rate: 3.1250e-05\n",
            "Epoch 32/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - loss: 0.2184 - mae: 0.3151 - val_loss: 0.2707 - val_mae: 0.3483 - learning_rate: 3.1250e-05\n",
            "Epoch 33/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2223 - mae: 0.3165 - val_loss: 0.2710 - val_mae: 0.3494 - learning_rate: 3.1250e-05\n",
            "Epoch 34/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2238 - mae: 0.3193 - val_loss: 0.2704 - val_mae: 0.3485 - learning_rate: 3.1250e-05\n",
            "Epoch 35/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2288 - mae: 0.3191 - val_loss: 0.2711 - val_mae: 0.3476 - learning_rate: 1.5625e-05\n",
            "Epoch 36/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - loss: 0.2291 - mae: 0.3197 - val_loss: 0.2708 - val_mae: 0.3473 - learning_rate: 1.5625e-05\n",
            "Epoch 37/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2210 - mae: 0.3156 - val_loss: 0.2706 - val_mae: 0.3466 - learning_rate: 1.5625e-05\n",
            "Epoch 38/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2257 - mae: 0.3199 - val_loss: 0.2707 - val_mae: 0.3469 - learning_rate: 1.5625e-05\n",
            "Epoch 39/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.2186 - mae: 0.3165 - val_loss: 0.2713 - val_mae: 0.3499 - learning_rate: 1.5625e-05\n",
            "Epoch 40/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2235 - mae: 0.3229 - val_loss: 0.2708 - val_mae: 0.3476 - learning_rate: 7.8125e-06\n",
            "Epoch 41/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2159 - mae: 0.3145 - val_loss: 0.2706 - val_mae: 0.3481 - learning_rate: 7.8125e-06\n",
            "Epoch 42/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.2133 - mae: 0.3132 - val_loss: 0.2707 - val_mae: 0.3475 - learning_rate: 7.8125e-06\n",
            "Epoch 43/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.2235 - mae: 0.3168 - val_loss: 0.2707 - val_mae: 0.3475 - learning_rate: 7.8125e-06\n",
            "Epoch 44/75\n",
            "\u001b[1m826/826\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.2158 - mae: 0.3158 - val_loss: 0.2709 - val_mae: 0.3472 - learning_rate: 7.8125e-06\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x787bb9921a10>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6caad27a"
      },
      "source": [
        "### Evaluating the Model\n",
        "\n",
        "This cell evaluates the trained model on the unseen test data and prints the test loss (Mean Squared Error) and Mean Absolute Error."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, mae = model.evaluate(X_test_scaled, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test MAE: {mae:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcoSyxr3t3DF",
        "outputId": "83b72ede-13e6-4c9f-b694-89320cf14360"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.2604 - mae: 0.3413\n",
            "Test Loss: 0.2653\n",
            "Test MAE: 0.3435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2f138c0"
      },
      "source": [
        "### Making Predictions\n",
        "\n",
        "This cell makes predictions on the scaled test data using the trained model and prints the first 5 predictions along with their corresponding actual values."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_scaled)\n",
        "print(\"Predictions:\", y_pred[:5].flatten())\n",
        "print(\"Actual values:\", y_test[:5].flatten())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuMXe1K7uKqO",
        "outputId": "caad4628-129d-498b-8a97-64bfe77e62d8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m129/129\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Predictions: [0.5238954 1.0314524 5.058307  2.591416  2.6866624]\n",
            "Actual values: [0.477   0.458   5.00001 2.186   2.78   ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d251f504"
      },
      "source": [
        "### Calculating Additional Evaluation Metrics\n",
        "\n",
        "This cell calculates and prints additional evaluation metrics: Mean Squared Error, Root Mean Squared Error, and R2 Score, providing a more comprehensive understanding of the model's performance on the test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "rmse = mse**0.5\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Root Mean Squared Error:\", rmse)\n",
        "print(\"R2 Score:\", r2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUluQnXufAp",
        "outputId": "1779be4a-4525-4991-d641-4bcc41d93be6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 0.2652855257312225\n",
            "Root Mean Squared Error: 0.5150587594937324\n",
            "R2 Score: 0.7975551677863629\n"
          ]
        }
      ]
    }
  ]
}