{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTrcas1M8qtCzAWr3fc13X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VidushiSharma31/ML-DL/blob/main/Deep%20Learning/iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22da8c26"
      },
      "source": [
        "# Iris Classification with a Neural Network\n",
        "\n",
        "This notebook demonstrates how to build and train a simple neural network using TensorFlow and Keras to classify the Iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9T2Omx3PeNC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ab85a473"
      },
      "source": [
        "## Data Loading and Preprocessing\n",
        "\n",
        "This section loads the Iris dataset and performs necessary preprocessing steps, including splitting the data into training and testing sets and scaling the features."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target"
      ],
      "metadata": {
        "id": "loERXkNUQon9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5CllqMClRu-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "gBH5BvHjSdQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([Dense(25, activation='relu'),\n",
        "                    Dense(15, activation='relu'),\n",
        "                    Dense(3, activation='linear')])"
      ],
      "metadata": {
        "id": "nP5uCExZSyPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e20fb04"
      },
      "source": [
        "## Model Definition and Training\n",
        "\n",
        "Here, we define the architecture of the neural network using Keras's Sequential API, compile the model with an optimizer and loss function, and train it on the preprocessed training data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QxQPubcSTqVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_scaled, y_train, epochs = 100, verbose=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GWpC0vLYUAIj",
        "outputId": "396b91c6-6d43-4e96-a02c-dde0a88ce1df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f6c96f2ddd0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b07637a"
      },
      "source": [
        "## Model Evaluation\n",
        "\n",
        "This section evaluates the trained model's performance on the test set and prints the accuracy."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kei8bqJqUdAh",
        "outputId": "92ec33ec-e944-4660-ea29-a9130da6a33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "694d7edf"
      },
      "source": [
        "## Prediction on Sample Data\n",
        "\n",
        "Finally, we use the trained model to make predictions on a few sample data points from the test set and compare the predicted classes with the true labels."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model.predict(X_test_scaled[:5])\n",
        "preds = tf.nn.softmax(logits)\n",
        "print(\"\\nPredicted probabilities (first 5 samples):\")\n",
        "print(preds.numpy())\n",
        "print(\"\\nPredicted classes:\", np.argmax(preds, axis=1))\n",
        "print(\"True labels:      \", y_test[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0nXj19tUhU0",
        "outputId": "5a00fe3e-ab7d-48be-b503-634ac5de988d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "\n",
            "Predicted probabilities (first 5 samples):\n",
            "[[1.2683860e-02 9.2682350e-01 6.0492657e-02]\n",
            " [9.9461597e-01 4.9024876e-03 4.8151531e-04]\n",
            " [1.9529312e-05 2.3069569e-04 9.9974972e-01]\n",
            " [2.0689946e-02 7.6215535e-01 2.1715476e-01]\n",
            " [1.4267525e-02 8.1427836e-01 1.7145413e-01]]\n",
            "\n",
            "Predicted classes: [1 0 2 1 1]\n",
            "True labels:       [1 0 2 1 1]\n"
          ]
        }
      ]
    }
  ]
}